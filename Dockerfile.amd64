# Use NVIDIA's CUDA-enabled Ubuntu 22.04 base image for AMD64
FROM nvidia/cuda:11.8.0-runtime-ubuntu22.04 AS runtime

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV CAMERA_TYPE=usb  

# Install basic dependencies
RUN apt-get update && apt-get install -y \
    python3-pip \
    python3-dev \
    cmake \
    libusb-1.0-0-dev \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libgtk-3-0 \
    libopencv-dev \
    python3-opencv \
    gstreamer1.0-tools \
    gstreamer1.0-plugins-good \
    gstreamer1.0-plugins-bad \
    gstreamer1.0-plugins-ugly \
    gstreamer1.0-libav \
    libgstreamer1.0-dev \
    libgstreamer-plugins-base1.0-dev \
    v4l-utils \
    wget \
    && apt-get clean && rm -rf /var/lib/apt/lists/*

# Stage for building librealsense from source (adapted from Intel's Dockerfile)
FROM runtime AS builder
RUN apt-get update && apt-get install -y \
    git \
    libssl-dev \
    libusb-1.0-0-dev \
    pkg-config \
    libgtk-3-dev \
    libglfw3-dev \
    libgl1-mesa-dev \
    libglu1-mesa-dev \
    at \
    && apt-get clean && rm -rf /var/lib/apt/lists/*

# Clone and build librealsense
WORKDIR /usr/src
RUN git clone https://github.com/IntelRealSense/librealsense.git \
    && cd librealsense \
    && mkdir build && cd build \
    && cmake \
    -DBUILD_EXAMPLES=false \
    -DBUILD_TOOLS=true \
    -DBUILD_UNIT_TESTS=false \
    -DBUILD_WITH_CUDA=false \
    -DCMAKE_BUILD_TYPE=Release .. \
    && make -j$(nproc) \
    && make install

# Final runtime image
FROM runtime

# Copy libraries and headers from builder stage
COPY --from=builder /usr/local /usr/local
COPY --from=builder /usr/lib /usr/lib

# Copy binaries from builder stage (e.g., rs-enumerate-devices, rs-fw-update)
COPY --from=builder /usr/local/bin /usr/local/bin

# Update library cache
RUN ldconfig

# Upgrade pip and install Python dependencies
RUN pip3 install --upgrade pip
RUN pip3 install \
    roboflow \
    requests \
    numpy \
    pyrealsense2 \
    flask

# Set working directory
WORKDIR /app

# Copy inference scripts and HTML template
COPY utils.py /app/utils.py
COPY inference_usb.py /app/inference_usb.py
COPY inference_realsense.py /app/inference_realsense.py
COPY inference_ip.py /app/inference_ip.py
COPY inference_tcp_server.py /app/inference_tcp_server.py
COPY templates/index.html /app/templates/index.html
COPY static /app/static

# Expose ports: 9001 for Roboflow inference, 5000 for Flask web server, 12345 for TCP server
EXPOSE 9001 5000 12345

# Command to run the appropriate inference script based on CAMERA_TYPE
CMD ["sh", "-c", "if [ \"$CAMERA_TYPE\" = \"realsense\" ]; then python3 inference_realsense.py; elif [ \"$CAMERA_TYPE\" = \"ip\" ]; then python3 inference_ip.py; elif [ \"$CAMERA_TYPE\" = \"tcp_server\" ]; then python3 inference_tcp_server.py; else python3 inference_usb.py; fi"]